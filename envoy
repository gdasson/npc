Below is a repo-ready, end-to-end implementation for:
	1.	Mutating webhook (injects initContainer + Envoy sidecar + ext-proc sidecar + volumes)
	2.	ext-proc server (Go gRPC ExternalProcessor; prefix-match policy; ForgeRock token caching + refresh)
	3.	egress-init (Go init binary: renders envoy.yaml + installs iptables for transparent interception)
	4.	How configs are read from ConfigMap + shared emptyDir path

Everything is static (no xDS control plane). You can later make ext-proc hot-reload the policy (this code already does periodic reload by mtime).

⸻

Repo layout

egress-gateway/
  cmd/
    webhook/
      main.go
    extproc/
      main.go
    egress-init/
      main.go
  internal/
    policy/
      policy.go
    tokens/
      tokens.go
    ipt/
      ipt.go
    render/
      render.go
  deploy/
    webhook/
      deployment.yaml
      service.yaml
      mutatingwebhookconfiguration.yaml
      namespace.yaml
    example-app/
      egress-configmap.yaml
      deployment.yaml
  Dockerfile.webhook
  Dockerfile.extproc
  Dockerfile.egress-init
  go.mod
  go.sum
  README.md


⸻

1) go.mod (root)

module example.com/egress-gateway

go 1.22

require (
	github.com/coreos/go-iptables v0.8.0
	github.com/envoyproxy/go-control-plane v0.13.4
	golang.org/x/sync v0.10.0
	google.golang.org/grpc v1.66.2
	gopkg.in/yaml.v3 v3.0.1
	k8s.io/api v0.30.3
	k8s.io/apimachinery v0.30.3
)


⸻

2) Policy config (internal/policy/policy.go)

This is the YAML schema stored in your per-app ConfigMap (egress.yaml). Both egress-init and ext-proc read it from the ConfigMap mount path.

package policy

import (
	"os"
	"time"

	"gopkg.in/yaml.v3"
)

type Rule struct {
	Profile  string            `yaml:"profile"`
	Prefix   string            `yaml:"prefix"`   // prefix match
	Scope    string            `yaml:"scope"`    // oauth scope
	Audience string            `yaml:"audience"` // optional
	Extra    map[string]string `yaml:"extra,omitempty"`
}

type Config struct {
	App struct {
		Name string `yaml:"name"`
	} `yaml:"app"`

	Ports struct {
		EnvoyHTTPListener  int `yaml:"envoy_http_listener"`
		EnvoyKafkaListener int `yaml:"envoy_kafka_listener"`
		ExtProcGRPC        int `yaml:"ext_proc_grpc"`
	} `yaml:"ports"`

	HTTP struct {
		InterceptPort  int  `yaml:"intercept_port"`   // port app uses for plain HTTP (default 80)
		UpgradeToHTTPS bool `yaml:"upgrade_to_https"` // default true

		TrustedCAFile string `yaml:"trusted_ca_file"` // for TLS origination to internet/hosts
		DFP           struct {
			MaxHosts        int    `yaml:"max_hosts"`
			DNSLookupFamily string `yaml:"dns_lookup_family"` // V4_ONLY etc
		} `yaml:"dfp"`

		Allow struct {
			DomainSuffixes []string `yaml:"domain_suffixes"`
		} `yaml:"allow"`

		ForgeRock struct {
			Enabled        bool   `yaml:"enabled"`
			FailMode       string `yaml:"fail_mode"` // "closed" or "open"
			ExtProcTimeout string `yaml:"ext_proc_timeout"`

			Bypass struct {
				AuthorityContains []string `yaml:"authority_contains"`
			} `yaml:"bypass"`

			TokenEndpoint string `yaml:"token_endpoint"`

			ClientAuth struct {
				Method          string `yaml:"method"` // client_secret_basic (this code)
				ClientID        string `yaml:"client_id"`
				ClientSecretEnv string `yaml:"client_secret_env"`
			} `yaml:"client_auth"`

			Rules []Rule `yaml:"rules"`
		} `yaml:"forgerock"`
	} `yaml:"http"`

	Kafka struct {
		Enabled     bool  `yaml:"enabled"`
		OriginalDst bool  `yaml:"original_dst"`
		Ports       []int `yaml:"ports"`
		TLS         struct {
			ClientCert string `yaml:"client_cert"`
			ClientKey  string `yaml:"client_key"`
			CACert     string `yaml:"ca_cert"`
		} `yaml:"tls"`
	} `yaml:"kafka"`
}

func Load(path string) (*Config, error) {
	b, err := os.ReadFile(path)
	if err != nil {
		return nil, err
	}
	var c Config
	if err := yaml.Unmarshal(b, &c); err != nil {
		return nil, err
	}
	ApplyDefaults(&c)
	return &c, nil
}

func ApplyDefaults(c *Config) {
	if c.Ports.EnvoyHTTPListener == 0 {
		c.Ports.EnvoyHTTPListener = 15001
	}
	if c.Ports.EnvoyKafkaListener == 0 {
		c.Ports.EnvoyKafkaListener = 15006
	}
	if c.Ports.ExtProcGRPC == 0 {
		c.Ports.ExtProcGRPC = 9000
	}

	if c.HTTP.InterceptPort == 0 {
		c.HTTP.InterceptPort = 80
	}
	if c.HTTP.TrustedCAFile == "" {
		c.HTTP.TrustedCAFile = "/etc/ssl/certs/ca-bundle.crt"
	}
	if c.HTTP.DFP.MaxHosts == 0 {
		c.HTTP.DFP.MaxHosts = 10000
	}
	if c.HTTP.DFP.DNSLookupFamily == "" {
		c.HTTP.DFP.DNSLookupFamily = "V4_ONLY"
	}
	// Default true if not specified
	if !c.HTTP.UpgradeToHTTPS {
		// keep false
	} else {
		c.HTTP.UpgradeToHTTPS = true
	}

	if c.HTTP.ForgeRock.FailMode == "" {
		c.HTTP.ForgeRock.FailMode = "closed"
	}
	if c.HTTP.ForgeRock.ExtProcTimeout == "" {
		c.HTTP.ForgeRock.ExtProcTimeout = "0.2s"
	}

	// Default lanes enabled unless set false
	if !c.Kafka.Enabled {
		// keep false
	} else {
		c.Kafka.Enabled = true
	}
	if !c.Kafka.OriginalDst {
		// keep false
	} else {
		c.Kafka.OriginalDst = true
	}

	if c.Kafka.TLS.ClientCert == "" {
		c.Kafka.TLS.ClientCert = "/etc/envoy/certs/tls.crt"
	}
	if c.Kafka.TLS.ClientKey == "" {
		c.Kafka.TLS.ClientKey = "/etc/envoy/certs/tls.key"
	}
	if c.Kafka.TLS.CACert == "" {
		c.Kafka.TLS.CACert = "/etc/envoy/certs/ca.crt"
	}
}

// Used by ext-proc hot reload (mtime polling)
func ModTime(path string) (time.Time, error) {
	st, err := os.Stat(path)
	if err != nil {
		return time.Time{}, err
	}
	return st.ModTime(), nil
}


⸻

3) Token cache + ForgeRock fetch (internal/tokens/tokens.go)

package tokens

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"strings"
	"sync"
	"time"

	"golang.org/x/sync/singleflight"
)

type Key struct {
	Profile  string
	Scope    string
	Audience string
}

func (k Key) String() string {
	return k.Profile + "|" + k.Scope + "|" + k.Audience
}

type Entry struct {
	Token  string
	Expiry time.Time
}

type Manager struct {
	mu sync.RWMutex
	m  map[string]Entry
	sf singleflight.Group
	Skew time.Duration
}

func NewManager(skew time.Duration) *Manager {
	if skew <= 0 {
		skew = 60 * time.Second
	}
	return &Manager{m: make(map[string]Entry), Skew: skew}
}

type Fetcher struct {
	TokenURL     string
	ClientID     string
	ClientSecret string
	HTTPClient   *http.Client

	Timeout time.Duration

	// Bulkhead (max in-flight token fetches)
	bulk chan struct{}

	// simple circuit breaker
	cbMu      sync.Mutex
	failures  int
	threshold int
	openUntil time.Time
	openFor   time.Duration
}

func NewFetcher(tokenURL, clientID, clientSecret string) *Fetcher {
	return &Fetcher{
		TokenURL:     tokenURL,
		ClientID:     clientID,
		ClientSecret: clientSecret,
		HTTPClient:   &http.Client{Timeout: 2 * time.Second},
		Timeout:      2 * time.Second,
		bulk:         make(chan struct{}, 4),
		threshold:    5,
		openFor:      10 * time.Second,
	}
}

func (f *Fetcher) allow() bool {
	f.cbMu.Lock()
	defer f.cbMu.Unlock()
	if time.Now().Before(f.openUntil) {
		return false
	}
	return true
}
func (f *Fetcher) onSuccess() {
	f.cbMu.Lock()
	defer f.cbMu.Unlock()
	f.failures = 0
	f.openUntil = time.Time{}
}
func (f *Fetcher) onFailure() {
	f.cbMu.Lock()
	defer f.cbMu.Unlock()
	f.failures++
	if f.failures >= f.threshold {
		f.openUntil = time.Now().Add(f.openFor)
	}
}

func (m *Manager) Get(ctx context.Context, key Key, fetch func(context.Context) (string, time.Time, error)) (string, time.Time, error) {
	k := key.String()
	now := time.Now()

	m.mu.RLock()
	if e, ok := m.m[k]; ok && e.Token != "" && now.Before(e.Expiry.Add(-m.Skew)) {
		m.mu.RUnlock()
		return e.Token, e.Expiry, nil
	}
	m.mu.RUnlock()

	v, err, _ := m.sf.Do(k, func() (any, error) {
		m.mu.RLock()
		if e, ok := m.m[k]; ok && e.Token != "" && time.Now().Before(e.Expiry.Add(-m.Skew)) {
			m.mu.RUnlock()
			return e, nil
		}
		m.mu.RUnlock()

		tok, exp, err := fetch(ctx)
		if err != nil {
			return nil, err
		}
		if tok == "" || exp.IsZero() {
			return nil, errors.New("empty token/expiry")
		}

		m.mu.Lock()
		m.m[k] = Entry{Token: tok, Expiry: exp}
		m.mu.Unlock()
		return m.m[k], nil
	})
	if err != nil {
		return "", time.Time{}, err
	}
	e := v.(Entry)
	return e.Token, e.Expiry, nil
}

func (f *Fetcher) FetchClientCredentials(ctx context.Context, scope, audience string, extra map[string]string) (string, time.Time, error) {
	if f.TokenURL == "" || f.ClientID == "" || f.ClientSecret == "" {
		return "", time.Time{}, errors.New("missing forgerock token url/client id/secret")
	}
	if !f.allow() {
		return "", time.Time{}, errors.New("forgerock circuit open")
	}

	// bulkhead
	select {
	case f.bulk <- struct{}{}:
		defer func() { <-f.bulk }()
	case <-ctx.Done():
		return "", time.Time{}, ctx.Err()
	}

	cctx, cancel := context.WithTimeout(ctx, f.Timeout)
	defer cancel()

	form := url.Values{}
	form.Set("grant_type", "client_credentials")
	if strings.TrimSpace(scope) != "" {
		form.Set("scope", scope)
	}
	if strings.TrimSpace(audience) != "" {
		form.Set("audience", audience)
	}
	for k, v := range extra {
		if strings.TrimSpace(k) != "" && strings.TrimSpace(v) != "" {
			form.Set(k, v)
		}
	}

	req, err := http.NewRequestWithContext(cctx, http.MethodPost, f.TokenURL, strings.NewReader(form.Encode()))
	if err != nil {
		f.onFailure()
		return "", time.Time{}, err
	}
	req.Header.Set("Content-Type", "application/x-www-form-urlencoded")
	req.SetBasicAuth(f.ClientID, f.ClientSecret)

	resp, err := f.HTTPClient.Do(req)
	if err != nil {
		f.onFailure()
		return "", time.Time{}, err
	}
	defer resp.Body.Close()

	body, _ := io.ReadAll(io.LimitReader(resp.Body, 1<<20))
	if resp.StatusCode < 200 || resp.StatusCode > 299 {
		f.onFailure()
		return "", time.Time{}, fmt.Errorf("forgerock token status=%d body=%q", resp.StatusCode, truncate(string(body), 300))
	}

	var parsed struct {
		AccessToken string `json:"access_token"`
		ExpiresIn   int64  `json:"expires_in"`
	}
	if err := json.Unmarshal(body, &parsed); err != nil {
		f.onFailure()
		return "", time.Time{}, err
	}
	if parsed.AccessToken == "" {
		f.onFailure()
		return "", time.Time{}, errors.New("token response missing access_token")
	}
	if parsed.ExpiresIn <= 0 {
		parsed.ExpiresIn = 300
	}

	f.onSuccess()
	exp := time.Now().Add(time.Duration(parsed.ExpiresIn) * time.Second)
	return parsed.AccessToken, exp, nil
}

func truncate(s string, max int) string {
	if len(s) <= max {
		return s
	}
	return s[:max] + "…"
}


⸻

4) iptables installer (internal/ipt/ipt.go)

package ipt

import (
	"fmt"
	"strconv"

	"github.com/coreos/go-iptables/iptables"
)

type Params struct {
	EnvoyUID     int
	ExtProcUID   int
	EnvoyHTTPPort int
	EnvoyKafkaPort int
	HTTPInterceptPort int
	KafkaPorts []int
}

func Install(p Params) error {
	ipt, err := iptables.New()
	if err != nil {
		return err
	}

	const table = "nat"
	const chain = "ENVOY_OUTBOUND"

	_ = ipt.NewChain(table, chain)
	if err := ipt.ClearChain(table, chain); err != nil {
		return err
	}

	// 0) localhost
	if err := ipt.AppendUnique(table, chain, "-d", "127.0.0.1/32", "-j", "RETURN"); err != nil {
		return err
	}
	// 1) uid excludes (avoid loops)
	if err := ipt.AppendUnique(table, chain, "-m", "owner", "--uid-owner", strconv.Itoa(p.EnvoyUID), "-j", "RETURN"); err != nil {
		return err
	}
	if err := ipt.AppendUnique(table, chain, "-m", "owner", "--uid-owner", strconv.Itoa(p.ExtProcUID), "-j", "RETURN"); err != nil {
		return err
	}
	// 2) DNS excludes
	if err := ipt.AppendUnique(table, chain, "-p", "udp", "--dport", "53", "-j", "RETURN"); err != nil {
		return err
	}
	if err := ipt.AppendUnique(table, chain, "-p", "tcp", "--dport", "53", "-j", "RETURN"); err != nil {
		return err
	}

	// 3) Kafka ports -> Envoy Kafka listener
	for _, kp := range p.KafkaPorts {
		if kp <= 0 {
			continue
		}
		if err := ipt.AppendUnique(table, chain, "-p", "tcp", "--dport", strconv.Itoa(kp), "-j", "REDIRECT", "--to-ports", strconv.Itoa(p.EnvoyKafkaPort)); err != nil {
			return err
		}
	}

	// 4) HTTP port -> Envoy HTTP listener
	if err := ipt.AppendUnique(table, chain, "-p", "tcp", "--dport", strconv.Itoa(p.HTTPInterceptPort), "-j", "REDIRECT", "--to-ports", strconv.Itoa(p.EnvoyHTTPPort)); err != nil {
		return err
	}

	// 5) hook OUTPUT -> chain
	if err := ipt.AppendUnique(table, "OUTPUT", "-p", "tcp", "-j", chain); err != nil {
		return fmt.Errorf("hook OUTPUT: %w", err)
	}

	return nil
}


⸻

5) Envoy renderer (internal/render/render.go)

Generates the Envoy config your Envoy sidecar will read from the shared emptyDir (/etc/envoy/envoy.yaml).

package render

import (
	"bytes"
	"strings"
	"text/template"

	"example.com/egress-gateway/internal/policy"
)

func EnvoyYAML(c *policy.Config) (string, error) {
	const tpl = `
node:
  id: {{.NodeID}}
  cluster: egress

admin:
  access_log_path: /tmp/admin_access.log
  address:
    socket_address: { address: 127.0.0.1, port_value: 9901 }

static_resources:
  listeners:
    - name: egress_http
      address:
        socket_address: { address: 0.0.0.0, port_value: {{.EnvoyHTTPPort}} }
      filter_chains:
        - filters:
            - name: envoy.filters.network.http_connection_manager
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                stat_prefix: egress_http
                normalize_path: true
                route_config:
                  name: egress_http_routes
                  virtual_hosts:
                    - name: egress
                      domains: ["*"]
                      routes:
                        - match: { prefix: "/" }
                          route: { cluster: dynamic_forward_proxy_cluster }
                http_filters:
{{- if .UpgradeToHTTPS }}
                  - name: envoy.filters.http.set_filter_state
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.set_filter_state.v3.Config
                      on_request_headers:
                        - object_key: "envoy.upstream.dynamic_host"
                          format_string:
                            text_format_source:
                              inline_string: "%REQ(:AUTHORITY)%"
                        - object_key: "envoy.upstream.dynamic_port"
                          format_string:
                            text_format_source:
                              inline_string: "443"
{{- end }}
{{- if .ForgeRockEnabled }}
                  - name: envoy.filters.http.ext_proc
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.ext_proc.v3.ExternalProcessor
                      grpc_service:
                        envoy_grpc:
                          cluster_name: ext-proc
                      processing_mode:
                        request_header_mode: SEND
                        response_header_mode: SKIP
                        request_body_mode: NONE
                        response_body_mode: NONE
                      message_timeout: {{.ExtProcTimeout}}
{{- end }}
                  - name: envoy.filters.http.dynamic_forward_proxy
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.dynamic_forward_proxy.v3.FilterConfig
                      dns_cache_config:
                        name: dfp_cache
                        dns_lookup_family: {{.DFPFamily}}
                        max_hosts: {{.DFPMaxHosts}}
                  - name: envoy.filters.http.router
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router

{{- if .KafkaEnabled }}
    - name: egress_kafka
      address:
        socket_address: { address: 0.0.0.0, port_value: {{.EnvoyKafkaPort}} }
      filter_chains:
        - filters:
            - name: envoy.filters.network.tcp_proxy
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxy
                stat_prefix: egress_kafka
                cluster: kafka_upstream
{{- end }}

  clusters:
    - name: ext-proc
      type: STATIC
      connect_timeout: 0.2s
      http2_protocol_options: {}
      load_assignment:
        cluster_name: ext-proc
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address: { address: 127.0.0.1, port_value: {{.ExtProcPort}} }

    - name: dynamic_forward_proxy_cluster
      connect_timeout: 2s
      cluster_type:
        name: envoy.clusters.dynamic_forward_proxy
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.clusters.dynamic_forward_proxy.v3.ClusterConfig
          dns_cache_config:
            name: dfp_cache
      transport_socket:
        name: envoy.transport_sockets.tls
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
          common_tls_context:
            validation_context:
              trusted_ca:
                filename: {{.TrustedCAFile}}

{{- if .KafkaEnabled }}
    - name: kafka_upstream
      connect_timeout: 2s
      type: ORIGINAL_DST
      lb_policy: CLUSTER_PROVIDED
      transport_socket:
        name: envoy.transport_sockets.tls
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
          common_tls_context:
            tls_certificates:
              - certificate_chain: { filename: {{.KafkaClientCert}} }
                private_key:       { filename: {{.KafkaClientKey}} }
            validation_context:
              trusted_ca: { filename: {{.KafkaCACert}} }
{{- end }}
`

	data := map[string]any{
		"NodeID":          strings.TrimSpace(c.App.Name) + "-egress",
		"EnvoyHTTPPort":   c.Ports.EnvoyHTTPListener,
		"EnvoyKafkaPort":  c.Ports.EnvoyKafkaListener,
		"ExtProcPort":     c.Ports.ExtProcGRPC,
		"UpgradeToHTTPS":  c.HTTP.UpgradeToHTTPS,
		"ForgeRockEnabled": c.HTTP.ForgeRock.Enabled,
		"ExtProcTimeout":  c.HTTP.ForgeRock.ExtProcTimeout,
		"DFPFamily":       c.HTTP.DFP.DNSLookupFamily,
		"DFPMaxHosts":     c.HTTP.DFP.MaxHosts,
		"TrustedCAFile":   c.HTTP.TrustedCAFile,
		"KafkaEnabled":    c.Kafka.Enabled,
		"KafkaClientCert": c.Kafka.TLS.ClientCert,
		"KafkaClientKey":  c.Kafka.TLS.ClientKey,
		"KafkaCACert":     c.Kafka.TLS.CACert,
	}

	t, err := template.New("envoy").Option("missingkey=error").Parse(tpl)
	if err != nil {
		return "", err
	}
	var buf bytes.Buffer
	if err := t.Execute(&buf, data); err != nil {
		return "", err
	}
	return strings.TrimSpace(buf.String()) + "\n", nil
}


⸻

6) egress-init (init container binary) — cmd/egress-init/main.go

Reads ConfigMap YAML at /etc/egress/egress.yaml, writes Envoy config into shared emptyDir (/work/envoy/envoy.yaml), then installs iptables.

package main

import (
	"flag"
	"fmt"
	"os"
	"path/filepath"

	"example.com/egress-gateway/internal/ipt"
	"example.com/egress-gateway/internal/policy"
	"example.com/egress-gateway/internal/render"
)

func main() {
	cfgPath := flag.String("config", "/etc/egress/egress.yaml", "path to egress.yaml")
	outEnvoy := flag.String("out-envoy", "/work/envoy/envoy.yaml", "output envoy.yaml")
	doIPT := flag.Bool("iptables", true, "install iptables")
	doRender := flag.Bool("render-envoy", true, "render envoy.yaml")

	envoyUID := flag.Int("envoy-uid", envInt("ENVOY_UID", 1337), "envoy uid")
	extprocUID := flag.Int("extproc-uid", envInt("EXTPROC_UID", 1338), "ext-proc uid")
	flag.Parse()

	c, err := policy.Load(*cfgPath)
	must(err)

	if *doRender {
		y, err := render.EnvoyYAML(c)
		must(err)
		must(writeAtomic(*outEnvoy, []byte(y)))
		fmt.Printf("rendered envoy.yaml -> %s\n", *outEnvoy)
	}

	if *doIPT {
		p := ipt.Params{
			EnvoyUID:           *envoyUID,
			ExtProcUID:         *extprocUID,
			EnvoyHTTPPort:      c.Ports.EnvoyHTTPListener,
			EnvoyKafkaPort:     c.Ports.EnvoyKafkaListener,
			HTTPInterceptPort:  c.HTTP.InterceptPort,
			KafkaPorts:         c.Kafka.Ports,
		}
		must(ipt.Install(p))
		fmt.Println("iptables installed")
	}
}

func envInt(k string, def int) int {
	v := os.Getenv(k)
	if v == "" {
		return def
	}
	var n int
	_, err := fmt.Sscanf(v, "%d", &n)
	if err != nil {
		return def
	}
	return n
}

func writeAtomic(path string, content []byte) error {
	dir := filepath.Dir(path)
	if err := os.MkdirAll(dir, 0o755); err != nil {
		return err
	}
	tmp := path + ".tmp"
	if err := os.WriteFile(tmp, content, 0o644); err != nil {
		return err
	}
	return os.Rename(tmp, path)
}

func must(err error) {
	if err != nil {
		fmt.Fprintln(os.Stderr, "ERROR:", err)
		os.Exit(1)
	}
}


⸻

7) ext-proc server — cmd/extproc/main.go
	•	Reads config from EGRESS_POLICY_FILE (default /etc/egress/egress.yaml)
	•	Periodically reloads if file mtime changed (so ConfigMap updates apply without pod restart)
	•	Longest prefix match on :path
	•	Optional allowed domain suffix enforcement
	•	Token caching per rule profile + scope + audience
	•	Injects Authorization: Bearer …

package main

import (
	"context"
	"fmt"
	"io"
	"log"
	"net"
	"os"
	"strings"
	"sync/atomic"
	"time"

	corev3 "github.com/envoyproxy/go-control-plane/envoy/config/core/v3"
	extprocv3 "github.com/envoyproxy/go-control-plane/envoy/service/ext_proc/v3"
	"google.golang.org/grpc"

	"example.com/egress-gateway/internal/policy"
	"example.com/egress-gateway/internal/tokens"
)

type liveConfig struct {
	cfg   *policy.Config
	rules []policy.Rule
}

type Processor struct {
	extprocv3.UnimplementedExternalProcessorServer

	policyPath string
	lastMTime  atomic.Value // time.Time
	live       atomic.Value // *liveConfig

	tokMgr  *tokens.Manager
	fetcher atomic.Value // *tokens.Fetcher
}

func main() {
	policyPath := getenv("EGRESS_POLICY_FILE", "/etc/egress/egress.yaml")
	listen := getenv("EXTPROC_LISTEN", "127.0.0.1:9000")

	p := &Processor{
		policyPath: policyPath,
		tokMgr:     tokens.NewManager(60 * time.Second),
	}

	// initial load
	if err := p.reload(); err != nil {
		log.Fatalf("policy load: %v", err)
	}
	go p.reloadLoop(3 * time.Second)

	lis, err := net.Listen("tcp", listen)
	if err != nil {
		log.Fatalf("listen: %v", err)
	}

	s := grpc.NewServer(grpc.MaxRecvMsgSize(4<<20), grpc.MaxSendMsgSize(4<<20))
	extprocv3.RegisterExternalProcessorServer(s, p)

	log.Printf("ext-proc listening=%s policy=%s", listen, policyPath)
	log.Fatal(s.Serve(lis))
}

func (p *Processor) reloadLoop(every time.Duration) {
	t := time.NewTicker(every)
	defer t.Stop()
	for range t.C {
		_ = p.reload() // log inside reload on failures
	}
}

func (p *Processor) reload() error {
	mt, err := policy.ModTime(p.policyPath)
	if err != nil {
		log.Printf("policy stat error: %v", err)
		return err
	}
	if v := p.lastMTime.Load(); v != nil {
		if mt.Equal(v.(time.Time)) {
			return nil
		}
	}

	c, err := policy.Load(p.policyPath)
	if err != nil {
		log.Printf("policy load error: %v", err)
		return err
	}

	// normalize prefixes (ensure trailing slash to avoid accidental matches)
	rules := make([]policy.Rule, 0, len(c.HTTP.ForgeRock.Rules))
	for _, r := range c.HTTP.ForgeRock.Rules {
		r.Prefix = normalizePrefix(r.Prefix)
		if r.Profile != "" && r.Prefix != "" {
			rules = append(rules, r)
		}
	}

	secretEnv := c.HTTP.ForgeRock.ClientAuth.ClientSecretEnv
	if secretEnv == "" {
		secretEnv = "FORGEROCK_CLIENT_SECRET"
	}
	clientSecret := strings.TrimSpace(os.Getenv(secretEnv))
	f := tokens.NewFetcher(c.HTTP.ForgeRock.TokenEndpoint, c.HTTP.ForgeRock.ClientAuth.ClientID, clientSecret)
	p.fetcher.Store(f)

	p.live.Store(&liveConfig{cfg: c, rules: rules})
	p.lastMTime.Store(mt)

	log.Printf("policy reloaded: app=%s rules=%d", c.App.Name, len(rules))
	return nil
}

func (p *Processor) Process(stream extprocv3.ExternalProcessor_ProcessServer) error {
	ctx := stream.Context()

	for {
		req, err := stream.Recv()
		if err == io.EOF {
			return nil
		}
		if err != nil {
			return err
		}

		switch r := req.Request.(type) {
		case *extprocv3.ProcessingRequest_RequestHeaders:
			lc := p.live.Load().(*liveConfig)
			cfg := lc.cfg

			h := r.RequestHeaders
			authority := strings.ToLower(headerGet(h.Headers, ":authority"))
			path := headerGet(h.Headers, ":path")
			path = normalizePath(path)

			// bypass recursion
			for _, s := range cfg.HTTP.ForgeRock.Bypass.AuthorityContains {
				if s != "" && strings.Contains(authority, strings.ToLower(s)) {
					if err := stream.Send(emptyHeadersResponse()); err != nil {
						return err
					}
					goto next
				}
			}

			// optional allowlist on domains
			if len(cfg.HTTP.Allow.DomainSuffixes) > 0 && !allowedSuffix(authority, cfg.HTTP.Allow.DomainSuffixes) {
				if cfg.HTTP.ForgeRock.FailMode == "open" {
					if err := stream.Send(emptyHeadersResponse()); err != nil {
						return err
					}
					goto next
				}
				if err := stream.Send(localReply(403, "egress host not allowed")); err != nil {
					return err
				}
				goto next
			}

			if !cfg.HTTP.ForgeRock.Enabled {
				if err := stream.Send(emptyHeadersResponse()); err != nil {
					return err
				}
				goto next
			}

			rule, ok := matchLongestPrefix(lc.rules, path)
			if !ok {
				// no-op if no rule
				if err := stream.Send(emptyHeadersResponse()); err != nil {
					return err
				}
				goto next
			}

			fetcher := p.fetcher.Load().(*tokens.Fetcher)
			key := tokens.Key{Profile: rule.Profile, Scope: rule.Scope, Audience: rule.Audience}

			tok, _, terr := p.tokMgr.Get(ctx, key, func(c context.Context) (string, time.Time, error) {
				return fetcher.FetchClientCredentials(c, rule.Scope, rule.Audience, rule.Extra)
			})
			if terr != nil {
				if cfg.HTTP.ForgeRock.FailMode == "open" {
					if err := stream.Send(emptyHeadersResponse()); err != nil {
						return err
					}
					goto next
				}
				if err := stream.Send(localReply(503, fmt.Sprintf("token unavailable: %v", terr))); err != nil {
					return err
				}
				goto next
			}

			resp := &extprocv3.ProcessingResponse{
				Response: &extprocv3.ProcessingResponse_RequestHeaders{
					RequestHeaders: &extprocv3.HeadersResponse{
						Response: &extprocv3.CommonResponse{
							HeaderMutation: &corev3.HeaderMutation{
								RemoveHeaders: []string{"authorization"},
								SetHeaders: []*corev3.HeaderValueOption{
									{Header: &corev3.HeaderValue{Key: "authorization", Value: "Bearer " + tok}},
								},
							},
						},
					},
				},
			}
			if err := stream.Send(resp); err != nil {
				return err
			}

		default:
			// headers-only mode -> ack
			if err := stream.Send(emptyHeadersResponse()); err != nil {
				return err
			}
		}

	next:
		continue
	}
}

func emptyHeadersResponse() *extprocv3.ProcessingResponse {
	return &extprocv3.ProcessingResponse{
		Response: &extprocv3.ProcessingResponse_RequestHeaders{
			RequestHeaders: &extprocv3.HeadersResponse{
				Response: &extprocv3.CommonResponse{},
			},
		},
	}
}

func localReply(status int32, body string) *extprocv3.ProcessingResponse {
	return &extprocv3.ProcessingResponse{
		Response: &extprocv3.ProcessingResponse_ImmediateResponse{
			ImmediateResponse: &extprocv3.ImmediateResponse{
				Status: &corev3.HttpStatus{Code: corev3.StatusCode(status)},
				Body:   body,
				Headers: &corev3.HeaderMap{Headers: []*corev3.HeaderValue{
					{Key: "content-type", Value: "text/plain"},
				}},
			},
		},
	}
}

func headerGet(hdrs *corev3.HeaderMap, key string) string {
	if hdrs == nil {
		return ""
	}
	k := strings.ToLower(key)
	for _, hv := range hdrs.Headers {
		if strings.ToLower(hv.Key) == k {
			return hv.Value
		}
	}
	return ""
}

func normalizePath(raw string) string {
	if i := strings.IndexByte(raw, '?'); i >= 0 {
		return raw[:i]
	}
	return raw
}

func normalizePrefix(p string) string {
	p = strings.TrimSpace(p)
	if p == "" {
		return ""
	}
	if !strings.HasPrefix(p, "/") {
		p = "/" + p
	}
	if !strings.HasSuffix(p, "/") {
		p = p + "/"
	}
	return p
}

func matchLongestPrefix(rules []policy.Rule, path string) (policy.Rule, bool) {
	var (
		found   bool
		best    policy.Rule
		bestLen int
	)
	for _, r := range rules {
		if strings.HasPrefix(path, r.Prefix) {
			if l := len(r.Prefix); l > bestLen {
				bestLen = l
				best = r
				found = true
			}
		}
	}
	return best, found
}

func allowedSuffix(authority string, suffixes []string) bool {
	// Strip port if present
	host := authority
	if i := strings.LastIndex(host, ":"); i > 0 && !strings.Contains(host[i+1:], "]") {
		// simple host:port; IPv6 not handled here (add if needed)
		host = host[:i]
	}
	host = strings.ToLower(host)
	for _, s := range suffixes {
		s = strings.ToLower(strings.TrimSpace(s))
		if s == "" {
			continue
		}
		if strings.HasSuffix(host, s) {
			return true
		}
	}
	return false
}

func getenv(k, def string) string {
	v := strings.TrimSpace(os.Getenv(k))
	if v == "" {
		return def
	}
	return v
}


⸻

8) Mutating webhook — cmd/webhook/main.go

Injects:
	•	initContainer egress-init (runs /egress-init ...)
	•	ext-proc sidecar
	•	envoy sidecar
	•	volumes: ConfigMap, emptyDir, kafka cert Secret
	•	reads injection inputs via annotations

package main

import (
	"crypto/tls"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"strings"

	admv1 "k8s.io/api/admission/v1"
	corev1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

const (
	annEnabled  = "egress.mycorp.io/enabled"
	annInjected = "egress.mycorp.io/injected"

	annConfigMap       = "egress.mycorp.io/configmap"
	annKafkaTLSSecret  = "egress.mycorp.io/kafka-tls-secret"
	annForgeRockSecret = "egress.mycorp.io/forgerock-secret"

	annEnvoyImage    = "egress.mycorp.io/envoy-image"
	annExtProcImage  = "egress.mycorp.io/extproc-image"
	annInitImage     = "egress.mycorp.io/init-image"
)

type PatchOp struct {
	Op    string      `json:"op"`
	Path  string      `json:"path"`
	Value interface{} `json:"value,omitempty"`
}

func main() {
	mux := http.NewServeMux()
	mux.HandleFunc("/mutate", handleMutate)
	mux.HandleFunc("/healthz", func(w http.ResponseWriter, _ *http.Request) { w.WriteHeader(200) })

	addr := getenv("LISTEN_ADDR", ":8443")
	certFile := getenv("TLS_CERT_FILE", "/tls/tls.crt")
	keyFile := getenv("TLS_KEY_FILE", "/tls/tls.key")

	srv := &http.Server{
		Addr:    addr,
		Handler: mux,
		TLSConfig: &tls.Config{
			MinVersion: tls.VersionTLS12,
		},
	}
	log.Printf("webhook listening on %s", addr)
	log.Fatal(srv.ListenAndServeTLS(certFile, keyFile))
}

func handleMutate(w http.ResponseWriter, r *http.Request) {
	body, err := io.ReadAll(r.Body)
	if err != nil {
		http.Error(w, "read body", 400)
		return
	}

	var review admv1.AdmissionReview
	if err := json.Unmarshal(body, &review); err != nil {
		http.Error(w, "bad admission review", 400)
		return
	}

	req := review.Request
	if req == nil {
		http.Error(w, "missing request", 400)
		return
	}

	if req.Kind.Kind != "Pod" || req.Operation != admv1.Create {
		writeReview(w, allow(req.UID))
		return
	}

	var pod corev1.Pod
	if err := json.Unmarshal(req.Object.Raw, &pod); err != nil {
		writeReview(w, deny(req.UID, fmt.Sprintf("decode pod: %v", err)))
		return
	}

	anns := pod.GetAnnotations()
	if anns == nil {
		anns = map[string]string{}
	}

	if strings.ToLower(anns[annEnabled]) != "true" {
		writeReview(w, allow(req.UID))
		return
	}
	if strings.ToLower(anns[annInjected]) == "true" {
		writeReview(w, allow(req.UID))
		return
	}

	cmName := strings.TrimSpace(anns[annConfigMap])
	kafkaSecret := strings.TrimSpace(anns[annKafkaTLSSecret])
	frSecret := strings.TrimSpace(anns[annForgeRockSecret])

	if cmName == "" {
		writeReview(w, deny(req.UID, "missing "+annConfigMap))
		return
	}
	if kafkaSecret == "" {
		writeReview(w, deny(req.UID, "missing "+annKafkaTLSSecret))
		return
	}
	if frSecret == "" {
		writeReview(w, deny(req.UID, "missing "+annForgeRockSecret))
		return
	}

	envoyImage := defaultIfEmpty(anns[annEnvoyImage], "envoyproxy/envoy:v1.31.0")
	extProcImage := defaultIfEmpty(anns[annExtProcImage], "myrepo/ext-proc:1.0.0")
	initImage := defaultIfEmpty(anns[annInitImage], "myrepo/egress-init:1.0.0")

	patch, err := buildPatch(&pod, cmName, kafkaSecret, frSecret, envoyImage, extProcImage, initImage)
	if err != nil {
		writeReview(w, deny(req.UID, err.Error()))
		return
	}

	patchBytes, _ := json.Marshal(patch)
	writeReview(w, &admv1.AdmissionResponse{
		UID:       req.UID,
		Allowed:   true,
		Patch:     patchBytes,
		PatchType: patchTypePtr(admv1.PatchTypeJSONPatch),
	})
}

func buildPatch(pod *corev1.Pod, cmName, kafkaSecret, frSecret, envoyImage, extProcImage, initImage string) ([]PatchOp, error) {
	var ops []PatchOp

	if pod.Annotations == nil {
		ops = append(ops, PatchOp{Op: "add", Path: "/metadata/annotations", Value: map[string]string{}})
	}
	ops = append(ops, PatchOp{Op: "add", Path: "/metadata/annotations/" + escapeJSONPointer(annInjected), Value: "true"})

	// volumes
	if pod.Spec.Volumes == nil {
		ops = append(ops, PatchOp{Op: "add", Path: "/spec/volumes", Value: []corev1.Volume{}})
	}
	ops = append(ops, PatchOp{Op: "add", Path: "/spec/volumes/-", Value: corev1.Volume{
		Name: "egress-config",
		VolumeSource: corev1.VolumeSource{
			ConfigMap: &corev1.ConfigMapVolumeSource{LocalObjectReference: corev1.LocalObjectReference{Name: cmName}},
		},
	}})
	ops = append(ops, PatchOp{Op: "add", Path: "/spec/volumes/-", Value: corev1.Volume{
		Name: "envoy-runtime",
		VolumeSource: corev1.VolumeSource{
			EmptyDir: &corev1.EmptyDirVolumeSource{},
		},
	}})
	ops = append(ops, PatchOp{Op: "add", Path: "/spec/volumes/-", Value: corev1.Volume{
		Name: "kafka-certs",
		VolumeSource: corev1.VolumeSource{
			Secret: &corev1.SecretVolumeSource{SecretName: kafkaSecret},
		},
	}})

	// initContainers
	if pod.Spec.InitContainers == nil {
		ops = append(ops, PatchOp{Op: "add", Path: "/spec/initContainers", Value: []corev1.Container{}})
	}
	init := corev1.Container{
		Name:  "egress-init",
		Image: initImage,
		Command: []string{"/egress-init"},
		Args: []string{
			"-config=/etc/egress/egress.yaml",
			"-out-envoy=/work/envoy/envoy.yaml",
			"-iptables=true",
			"-render-envoy=true",
		},
		SecurityContext: &corev1.SecurityContext{
			RunAsUser: ptrI64(0),
			Capabilities: &corev1.Capabilities{
				Add: []corev1.Capability{"NET_ADMIN"},
			},
			AllowPrivilegeEscalation: ptrB(false),
		},
		Env: []corev1.EnvVar{
			{Name: "ENVOY_UID", Value: "1337"},
			{Name: "EXTPROC_UID", Value: "1338"},
		},
		VolumeMounts: []corev1.VolumeMount{
			{Name: "egress-config", MountPath: "/etc/egress", ReadOnly: true},
			{Name: "envoy-runtime", MountPath: "/work"},
		},
	}
	ops = append(ops, PatchOp{Op: "add", Path: "/spec/initContainers/-", Value: init})

	// containers exist?
	if len(pod.Spec.Containers) == 0 {
		return nil, fmt.Errorf("pod has no containers")
	}

	// ext-proc sidecar
	extproc := corev1.Container{
		Name:  "ext-proc",
		Image: extProcImage,
		SecurityContext: &corev1.SecurityContext{
			RunAsUser:                ptrI64(1338),
			RunAsNonRoot:             ptrB(true),
			ReadOnlyRootFilesystem:   ptrB(true),
			AllowPrivilegeEscalation: ptrB(false),
		},
		Env: []corev1.EnvVar{
			{Name: "EGRESS_POLICY_FILE", Value: "/etc/egress/egress.yaml"},
			{Name: "EXTPROC_LISTEN", Value: "127.0.0.1:9000"},
			{
				Name: "FORGEROCK_CLIENT_SECRET",
				ValueFrom: &corev1.EnvVarSource{
					SecretKeyRef: &corev1.SecretKeySelector{
						LocalObjectReference: corev1.LocalObjectReference{Name: frSecret},
						Key:                  "client_secret",
					},
				},
			},
		},
		Ports: []corev1.ContainerPort{
			{Name: "grpc", ContainerPort: 9000},
		},
		VolumeMounts: []corev1.VolumeMount{
			{Name: "egress-config", MountPath: "/etc/egress", ReadOnly: true},
		},
	}
	ops = append(ops, PatchOp{Op: "add", Path: "/spec/containers/-", Value: extproc})

	// envoy sidecar
	envoy := corev1.Container{
		Name:  "envoy",
		Image: envoyImage,
		Args:  []string{"-c", "/etc/envoy/envoy.yaml", "--log-level", "info"},
		SecurityContext: &corev1.SecurityContext{
			RunAsUser:                ptrI64(1337),
			RunAsNonRoot:             ptrB(true),
			ReadOnlyRootFilesystem:   ptrB(true),
			AllowPrivilegeEscalation: ptrB(false),
		},
		Ports: []corev1.ContainerPort{
			{Name: "egress-http", ContainerPort: 15001},
			{Name: "egress-kafka", ContainerPort: 15006},
			{Name: "admin", ContainerPort: 9901},
		},
		VolumeMounts: []corev1.VolumeMount{
			{Name: "envoy-runtime", MountPath: "/etc/envoy", ReadOnly: true},
			{Name: "kafka-certs", MountPath: "/etc/envoy/certs", ReadOnly: true},
		},
	}
	ops = append(ops, PatchOp{Op: "add", Path: "/spec/containers/-", Value: envoy})

	return ops, nil
}

func writeReview(w http.ResponseWriter, resp *admv1.AdmissionResponse) {
	out := admv1.AdmissionReview{
		TypeMeta: metav1.TypeMeta{APIVersion: "admission.k8s.io/v1", Kind: "AdmissionReview"},
		Response: resp,
	}
	b, _ := json.Marshal(out)
	w.Header().Set("Content-Type", "application/json")
	_, _ = w.Write(b)
}

func allow(uid string) *admv1.AdmissionResponse {
	return &admv1.AdmissionResponse{UID: uid, Allowed: true}
}

func deny(uid, msg string) *admv1.AdmissionResponse {
	return &admv1.AdmissionResponse{
		UID:     uid,
		Allowed: false,
		Result:  &metav1.Status{Message: msg},
	}
}

func escapeJSONPointer(s string) string {
	s = strings.ReplaceAll(s, "~", "~0")
	s = strings.ReplaceAll(s, "/", "~1")
	return s
}

func getenv(k, def string) string {
	v := strings.TrimSpace(os.Getenv(k))
	if v == "" {
		return def
	}
	return v
}
func defaultIfEmpty(v, def string) string {
	v = strings.TrimSpace(v)
	if v == "" {
		return def
	}
	return v
}
func patchTypePtr(pt admv1.PatchType) *admv1.PatchType { return &pt }
func ptrI64(v int64) *int64                            { return &v }
func ptrB(v bool) *bool                                { return &v }


⸻

9) Dockerfiles

Dockerfile.egress-init

FROM golang:1.22 AS build
WORKDIR /src
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o /out/egress-init ./cmd/egress-init

FROM gcr.io/distroless/static:nonroot
COPY --from=build /out/egress-init /egress-init
USER 0
ENTRYPOINT ["/egress-init"]

Note: distroless + iptables won’t work because iptables binary isn’t present.
For iptables, use a minimal image with iptables installed. Here’s the correct one:

Replace the runtime stage with Alpine + iptables:

FROM alpine:3.20
RUN apk add --no-cache iptables
COPY --from=build /out/egress-init /egress-init
USER 0
ENTRYPOINT ["/egress-init"]

Dockerfile.extproc

FROM golang:1.22 AS build
WORKDIR /src
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o /out/ext-proc ./cmd/extproc

FROM gcr.io/distroless/static:nonroot
COPY --from=build /out/ext-proc /ext-proc
USER 1338
ENTRYPOINT ["/ext-proc"]

Dockerfile.webhook

FROM golang:1.22 AS build
WORKDIR /src
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o /out/webhook ./cmd/webhook

FROM gcr.io/distroless/static:nonroot
COPY --from=build /out/webhook /webhook
USER 65532
ENTRYPOINT ["/webhook"]


⸻

10) Example per-app ConfigMap (deploy/example-app/egress-configmap.yaml)

apiVersion: v1
kind: ConfigMap
metadata:
  name: egress-config-orders
data:
  egress.yaml: |
    app:
      name: orders
    ports:
      envoy_http_listener: 15001
      envoy_kafka_listener: 15006
      ext_proc_grpc: 9000

    http:
      intercept_port: 80
      upgrade_to_https: true
      trusted_ca_file: /etc/ssl/certs/ca-bundle.crt
      dfp:
        max_hosts: 10000
        dns_lookup_family: V4_ONLY
      allow:
        domain_suffixes:
          - ".mycorp.internal"
          - ".trustedvendor.com"
      forgerock:
        enabled: true
        fail_mode: closed
        ext_proc_timeout: 0.2s
        bypass:
          authority_contains:
            - "forgerock.example.com"
        token_endpoint: "https://forgerock.example.com/am/oauth2/access_token"
        client_auth:
          method: client_secret_basic
          client_id: "orders-egress"
          client_secret_env: "FORGEROCK_CLIENT_SECRET"
        rules:
          - profile: "orders-admin"
            prefix: "/orders/admin/"
            scope: "orders.admin"
            audience: "orders-api"
          - profile: "orders"
            prefix: "/orders/"
            scope: "orders.read"
            audience: "orders-api"

    kafka:
      enabled: true
      original_dst: true
      ports: [9092, 9093]
      tls:
        client_cert: "/etc/envoy/certs/tls.crt"
        client_key: "/etc/envoy/certs/tls.key"
        ca_cert: "/etc/envoy/certs/ca.crt"


⸻

11) Example app Deployment using webhook (deploy/example-app/deployment.yaml)

This is all the app needs: annotations that tell the webhook which ConfigMap + Secrets to mount.

apiVersion: apps/v1
kind: Deployment
metadata:
  name: orders
spec:
  replicas: 1
  selector:
    matchLabels: { app: orders }
  template:
    metadata:
      labels: { app: orders }
      annotations:
        egress.mycorp.io/enabled: "true"
        egress.mycorp.io/configmap: "egress-config-orders"
        egress.mycorp.io/kafka-tls-secret: "orders-kafka-mtls"         # cert-manager secret
        egress.mycorp.io/forgerock-secret: "forgerock-client-orders"   # contains client_secret
        # optional overrides:
        # egress.mycorp.io/envoy-image: "envoyproxy/envoy:v1.31.0"
        # egress.mycorp.io/extproc-image: "myrepo/ext-proc:1.0.0"
        # egress.mycorp.io/init-image: "myrepo/egress-init:1.0.0"
    spec:
      containers:
        - name: app
          image: myrepo/orders:1.0.0
          ports:
            - containerPort: 8080


⸻

12) Webhook deployment manifests (quick)

You’ll need TLS for the webhook and a CA bundle in MutatingWebhookConfiguration. I’m keeping it minimal; you can use cert-manager to issue and inject the CA bundle.
	•	deploy/webhook/namespace.yaml
	•	deploy/webhook/deployment.yaml
	•	deploy/webhook/service.yaml
	•	deploy/webhook/mutatingwebhookconfiguration.yaml

If you want, tell me if you use cert-manager for the webhook cert too, and I’ll provide the exact Certificate + annotations to auto-populate caBundle.

⸻

How configs are read (exactly what you asked)

From ConfigMap (read-only mount)

Webhook injects a volume:
	•	egress-config → mounted at /etc/egress
	•	file path: /etc/egress/egress.yaml

Both ext-proc and egress-init read this file:
	•	ext-proc: EGRESS_POLICY_FILE=/etc/egress/egress.yaml
	•	egress-init: -config=/etc/egress/egress.yaml

Shared path between init and Envoy (emptyDir)

Webhook injects:
	•	envoy-runtime emptyDir mounted at:
	•	init: /work
	•	envoy: /etc/envoy (read-only)

Init writes:
	•	/work/envoy/envoy.yaml

Envoy reads:
	•	/etc/envoy/envoy.yaml

Secrets (cert-manager + ForgeRock secret)

Webhook injects:
	•	kafka-certs secret volume mounted to Envoy at /etc/envoy/certs
	•	ForgeRock client secret via env var in ext-proc:
	•	secret key client_secret → FORGEROCK_CLIENT_SECRET

⸻

Next things I’d add in your repo (optional but practical)
	•	Readiness probes (Envoy admin ready, ext-proc gRPC health)
	•	More robust authority parsing (IPv6 host:port)
	•	ORIGINAL_DST + TLS for Kafka is correct, but make sure your Kafka clients really connect to brokers directly (most do)

If you want, paste your webhook namespace + how you prefer webhook TLS to be managed (cert-manager or manual), and I’ll provide the final deploy/webhook/*.yaml set with CA injection and RBAC.